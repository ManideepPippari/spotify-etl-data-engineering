ğŸµ Spotify End-to-End Data Engineering Pipeline (Production-Grade)

![Tests](https://img.shields.io/badge/tests-passing-brightgreen)
![Python](https://img.shields.io/badge/python-3.9+-blue)
![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20Lambda%20%7C%20Glue%20%7C%20Athena-orange)
![Databricks](https://img.shields.io/badge/Databricks-PySpark-red)
![Snowflake](https://img.shields.io/badge/Snowflake-ELT-blue)
![PowerBI](https://img.shields.io/badge/Power%20BI-Dashboard-yellow)

AWS S3 | Lambda | EventBridge | Glue | Athena | Docker Airflow | Snowflake | Databricks (PySpark) | Power BI

This project demonstrates a full, enterprise-level ETL + ELT pipeline, ingesting Spotify artist track data, transforming it across multi-cloud systems, and loading it into analytics and BI layers.

Built using 11 industry technologies, this system simulates what a real Data Engineering team builds for scalable analytics.

Note: This is a portfolio project designed to demonstrate real-world data engineering patterns, tooling integration, and production-style workflows. All infrastructure was created, validated, and deprovisioned responsibly to avoid unnecessary cloud costs.


ğŸ¯ Project Intent

This project was built to mirror how modern data engineering teams design, test, and operate analytics pipelines in production environments.

The focus areas include:
	â€¢	End-to-end pipeline architecture
	â€¢	Cross-platform data movement (AWS â†’ Databricks â†’ Snowflake â†’ BI)
	â€¢	Bronze / Silver / Gold data modeling
	â€¢	Data quality validation across systems
	â€¢	Cost-aware cloud usage and deprovisioning
	â€¢	Clear documentation and testability

This is not a tutorial project, but a realistic, production-style system suitable for portfolio review and technical interviews.


ğŸ§  High-Level Architecture

![Architecture Diagram](architecture/spotify_etl_architecture.png)

Full Workflow
	1.	Spotify API â†’ Lambda (Ingestion)
	2.	Lambda â†’ S3 (Raw/Processed Data)
	3.	Glue Crawler â†’ Athena (Schema inference + querying)
	4.	Airflow (Docker) â†’ Orchestrates Athena, Glue, Databricks, Snowflake jobs
	5.	Databricks (PySpark) â†’ Bronze â†’ Silver â†’ Gold tables
	6.	Snowflake â†’ ELT transformations + stored procedures + tasks
	7.	Power BI â†’ Final visualization layer



    ğŸ›  Tech Stack

Cloud: AWS S3, Lambda, EventBridge, Glue, Athena
Orchestration: Apache Airflow (Docker)
Processing: Databricks, PySpark
Data Warehouse: Snowflake
Analytics: Power BI
Programming: Python 3
CI/CD: Git + GitHub


ğŸ“‚ Repository Structure


spotify-etl-data-engineering/
â”‚
â”œâ”€â”€ src/                       # Local ingestion & transformation logic
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ transform/
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ lambda/                    # AWS Lambda ingestion & transform functions
â”‚
â”œâ”€â”€ Eventbridge/               # EventBridge schedules & setup docs
â”‚
â”œâ”€â”€ glue/
â”‚   â”œâ”€â”€ crawler_config.json
â”‚   â”œâ”€â”€ processed_schema.json
â”‚   â”œâ”€â”€ transformed_schema.json
â”‚   â””â”€â”€ s3_samples/
â”‚
â”œâ”€â”€ athena/
â”‚   â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ workgroup_config.json
â”‚   â”œâ”€â”€ results_samples/
â”‚   â””â”€â”€ top10_artist_stats_query.sql
â”‚
â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ queries/
â”‚   â”œâ”€â”€ tables/
â”‚   â””â”€â”€ result_samples/
â”‚
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ queries/
â”‚   â”œâ”€â”€ procedures/
â”‚   â”œâ”€â”€ tables/
â”‚   â””â”€â”€ results_samples/
â”‚
â”œâ”€â”€ dags/                      # Airflow DAGs
â”‚
â”œâ”€â”€ s3/                        # Local S3 object samples
â”‚
â”œâ”€â”€ powerbi/                   # Power BI dashboards & screenshots
â”‚
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md    # Testing & validation notes
â”œâ”€â”€ PERFORMANCE_METRICS.md     # Performance & cost observations
â””â”€â”€ README.md               



ğŸ§ Spotify Ingestion

Python | Spotify API

Features
	â€¢	Fetches top tracks from multiple artists
	â€¢	Automatically retrieves OAuth access tokens
	â€¢	Saves raw and processed CSV outputs
	â€¢	Fully environment-variable driven (no secrets in repo)

AWS Lambda Ingest
	â€¢	Calls Spotify API
	â€¢	Cleans and structures data
	â€¢	Writes processed output to S3 (spotify/processed/)

EventBridge Integration
	â€¢	Scheduled hourly execution
	â€¢	JSON configuration included
	â€¢	End-to-end setup documentation provided


â˜ AWS Data Layer

spotify/
    raw/
    processed/
    transformed/
    athena-results/

    ğŸŸ£  AWS Glue & Athena 

Glue Crawler
	â€¢	Automatically infers schemas
	â€¢	Creates processed and transformed tables
	â€¢	Configuration files included

Athena
	â€¢	Dedicated analytics workgroup
	â€¢	Predefined SQL analytics queries
	â€¢	Sample query results included



âš™ Orchestration
    ğŸŸ¢ Airflow (Docker)

The Airflow DAG orchestrates the full pipeline:
	1.	Run local Spotify extraction
	2.	Upload data to S3
	3.	Trigger Glue crawler
	4.	Execute Athena analytics
	5.	Trigger Databricks workflows
	6.	Execute Snowflake procedures
	7.	Run data quality checks
	8.	Produce final pipeline summary

Folder: dags/spotify_etl_dag.py
Includes:
	â€¢	XCom usage
	â€¢	Snowflake operators
	â€¢	HTTP hooks (Databricks)
	â€¢	Retry logic & error handling
	â€¢	Inline documentation


ğŸ”¥ Databricks
PySpark | Delta-Lake

Notebook Assets
	â€¢	Spotify_Spark_Processing.ipynb
	â€¢	Python script version
	â€¢	HTML export

Bronze Layer
	â€¢	Raw ingest from S3
	â€¢	Table: spotify_tracks_bronze

Silver Layer
	â€¢	Deduplication
	â€¢	Type casting
	â€¢	Calculated columns
	â€¢	Table: spotify_tracks_silver

Gold Layer
	â€¢	Aggregations & analytics features
	â€¢	Table: spotify_tracks_gold
	â€¢	Popularity summary outputs

Databricks job config also included:
	â€¢	cluster config markdown
	â€¢	job markdown
	â€¢	SQL queries
	â€¢	Result samples


â„ Snowflake
Warehouse | ELT | Automation

Includes:
	â€¢	Database, schema, warehouse setup
	â€¢	External stages & file formats
	â€¢	Bronze / Silver / Gold tables
	â€¢	Stored procedures
	â€¢	Scheduled tasks
	â€¢	Data quality checks
	â€¢	Result samples


ğŸ“Š Power BI

Analytics & Visualization

Dashboards include:
	â€¢	Artist popularity
	â€¢	Track duration distribution
	â€¢	Explicit vs non-explicit analysis
	â€¢	Bronze â†’ Silver â†’ Gold row comparison
	â€¢	Release trends


 ğŸ§ª Data Quality Checks (Across Platforms)

Implemented validations include:
	â€¢	Athena vs Snowflake row counts
	â€¢	Gold-layer aggregation checks
	â€¢	Popularity summary verification
	â€¢	Sample DQ outputs included



	ğŸ§ª Testing & Quality Assurance

This project includes a focused, practical test suite to validate core pipeline logic
without requiring live cloud infrastructure.

Validated components include:
	â€¢	Spotify ingestion (local & Lambda)
	â€¢	Transformation logic (duration, categorization, timestamps)
	â€¢	S3-triggered Lambda behavior
	â€¢	Error-handling scenarios

Run Tests:
pip install -r tests/requirements_test.txt
pytest -q

Run specific tests:
pytest tests/test_extract_local.py -q
pytest tests/test_spotify_lambda_ingest.py -q
pytest tests/test_spotify_lambda_transform.py -q

ğŸ“– Detailed testing notes: IMPLEMENTATION_GUIDE.md



ğŸ“Š Performance & Cost Notes 

Pipeline execution behavior and cost considerations were evaluated during development.
	â€¢	End-to-end pipeline validated successfully
	â€¢	Data quality confirmed across platforms
	â€¢	Infrastructure deprovisioned after validation

ğŸ“Š Full details available in PERFORMANCE_METRICS.md


ğŸ” Environment Configuration

All credentials are handled via environment variables only.
No secrets are committed to this repository.

Example:
SPOTIFY_CLIENT_ID=your_client_id
SPOTIFY_CLIENT_SECRET=your_client_secret

AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
AWS_DEFAULT_REGION=us-east-2

S3_BUCKET_NAME=your-bucket


ğŸ¥ End-to-End Pipeline Demo (4 minutes)

ğŸ“Œ **Watch the full automated pipeline walkthrough:**  
â–¶ï¸ [`pipeline_demo.mp4`](demo/pipeline_demo.mp4)

This video demonstrates:
- Apache Airflow orchestration (Dockerized)
- Spotify API ingestion using Python
- Databricks Bronze â†’ Silver â†’ Gold processing
- AWS Glue crawler automation
- Analytics validation in Athena & Snowflake
- Production-style end-to-end execution

The demo shows a real pipeline run with orchestration, processing, and validation â€” not static screenshots.



ğŸ§© How to Run This Project (Locally / Cloud)

Local (Airflow + Docker)
docker-compose up -d

Upload DAG: dags/spotify_etl_dag.py

Access UI: http://localhost:8080

Quick Validation: pytest -q
